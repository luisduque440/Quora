{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quora pairs Kaggle competition\n",
    "Creation of a dictionary\n",
    "@author: Luis Duque\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import string\n",
    "import re, math\n",
    "from string import punctuation\n",
    "from difflib import SequenceMatcher\n",
    "from collections import Counter\n",
    "from operator import xor\n",
    "from IPython.display import clear_output\n",
    "import gensim\n",
    "from gensim.models import Word2Vec ## We load a pretrained Word2Vect model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "############    CREATION OF THE DICTIONARY   ###################################################################\n",
    "################################################################################################################\n",
    "# The main function in this cell is CreateDictionary(Df1, Df2):\n",
    "# The goal of this function is to find the relevance of each word in Df1 (the training data set)\n",
    "## Very simple comparison between strings\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "# Note many of the \"fuzzy\" functions have similars already implemented in pythons fuzzywuzzy module   \n",
    "def FuzzyWordInList(Word, List):\n",
    "    if Word in List: \n",
    "        return 1\n",
    "    \n",
    "    for cWord in List:\n",
    "        if FuzzySame(Word, cWord):\n",
    "            return 1;\n",
    "    return 0\n",
    "\n",
    "\n",
    "def FuzzyFindRepresentative(Word, List): \n",
    "    if Word in List: \n",
    "        return Word\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "def FuzzyIntersection(Bag1, Bag2):\n",
    "    Intersection = []\n",
    "    for Word in Bag1:\n",
    "        if FuzzyWordInList(Word, Bag2):\n",
    "            Intersection.append(Word)\n",
    "    return Intersection\n",
    "\n",
    "\n",
    "def FuzzyUnion(Bag1, Bag2):\n",
    "    Set1 = set(Bag1)-set(FuzzyIntersection(Bag1, Bag2))\n",
    "    Set2 = set(Bag2)\n",
    "    return list(Set1.union(Set2))\n",
    "\n",
    "\n",
    "def FuzzyWordsInOneList(Bag1, Bag2):\n",
    "    Lista = []\n",
    "    for Word in Bag1:\n",
    "        if not FuzzyWordInList(Word, Bag2):\n",
    "            Lista.append(Word)\n",
    "        \n",
    "    for Word in Bag2:\n",
    "        if not FuzzyWordInList(Word, Bag1):\n",
    "            Lista.append(Word)\n",
    "    return Lista\n",
    "\n",
    "\n",
    "def FuzzySame(Word1, Word2):   \n",
    "    comparison = similar(Word1, Word2)\n",
    "    if comparison > 0.8:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "\n",
    "def strip_punctuation_nums(s):\n",
    "    s = s.lower()\n",
    "    return ''.join(c for c in s if c not in punctuation+\"â€™0123456789\")\n",
    "\n",
    "\n",
    "def StringToList_Nonums(Doc): ## Auxiliar function that converts a string of characters into a Bag of words\n",
    "    nopunctuationlower = strip_punctuation_nums(Doc)\n",
    "    tokens = nopunctuationlower.split()\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def DictionaryToCSV(Dictionary, filename): # Saves the global hash table Dictionary to a .csv file\n",
    "    Wordlist = []\n",
    "    Quotient1list = []\n",
    "    Quotient2list = []\n",
    "\n",
    "    for word in Dictionary:\n",
    "        Quotients = Dictionary[word]\n",
    "        Wordlist.append(word)\n",
    "        Quotient1list.append(Quotients[0])\n",
    "        Quotient2list.append(Quotients[1])\n",
    "\n",
    "    DictDf = pd.DataFrame(   ## This creates the data frame with the whole Dictionary\n",
    "    {'Quotient1': Quotient1list,\n",
    "    'Quotient2': Quotient2list,\n",
    "     'Words': Wordlist\n",
    "    })\n",
    "\n",
    "    DictDf.to_csv(filename, header = True)  ## This creates the csv file of the dictionary\n",
    "    return\n",
    "\n",
    "\n",
    "def RepeatedWordsToCSV(RepeatedWords, filename): # Saves the global hash table RepeatedWords to a .csv file  (this is just for exploratory purposes)\n",
    "    ## We create a file where we list words that are similar (Just to have an idea of what is going on)\n",
    "    Wordlist = []\n",
    "    SimilarWords  = []\n",
    "    for word in RepeatedWords:\n",
    "        Wordlist.append(word)\n",
    "        SimilarWords.append(RepeatedWords[word])\n",
    "\n",
    "    SimilarDf = pd.DataFrame(   ## This creates the data frame listing related words\n",
    "    {'Similar': SimilarWords,\n",
    "    'Words': Wordlist\n",
    "    })\n",
    "\n",
    "    SimilarDf.to_csv(filename, header = True)  ## This creates the csv file of Similar words\n",
    "    return \n",
    "\n",
    "\n",
    "# The following function use word2vect pretrained from google. Given a Dictionary this will extend it using word2vect.\n",
    "# EXAMPLE: say we run PossibleNewWord(\"colombia\") and \"colombia\" is not in the Dictionary. This function will find the \n",
    "# word in our dictionary that is closest to \"colombia\" using word2vect (say the closest one is \"india\") and \n",
    "# assign Dictionary2[\"colombia\"] = Dictionary[\"india\"]. \n",
    "def PossibleNewWord(myWord, Dictionary, Dictionary2, RepeatedWords):\n",
    "    if (myWord in Dictionary) or (myWord in Dictionary2):\n",
    "        return\n",
    "        \n",
    "    elif myWord in model:  \n",
    "        maxcomparison = -1\n",
    "        closestMatch = myWord\n",
    "        for Word in Dictionary:\n",
    "            if Word in model:\n",
    "                comparison = model.similarity(myWord, Word)\n",
    "                if comparison > maxcomparison:\n",
    "                    closestMatch = Word\n",
    "                    maxcomparison = comparison\n",
    "        \n",
    "        Dictionary2[myWord] = Dictionary[closestMatch]\n",
    "\n",
    "    else:\n",
    "        maxcomparison = -1\n",
    "        closestMatch = myWord\n",
    "        for Word in Dictionary:\n",
    "            comparison = similar(myWord, Word)\n",
    "            if comparison > maxcomparison:\n",
    "                closestMatch = Word\n",
    "                maxcomparison = comparison\n",
    "            \n",
    "        Dictionary2[myWord] = Dictionary[closestMatch]\n",
    "    \n",
    "    if closestMatch in RepeatedWords:\n",
    "        RepeatedWords[closestMatch].append(myWord)\n",
    "    else:\n",
    "        RepeatedWords[closestMatch]=[myWord]\n",
    "    return;\n",
    "\n",
    "\n",
    "# Feeds the initialized Dictionary with every possible word\n",
    "def FeedDictionary(Df1, Df2, Dictionary, Dictionary2, RepeatedWords):    \n",
    "    for index, row in Df1.iterrows():\n",
    "        Bags = set( StringToList_Nonums(str(row['question1'])) + StringToList_Nonums(str(row['question2'])))\n",
    "        for word in Bags:\n",
    "            PossibleNewWord(word, Dictionary, Dictionary2, RepeatedWords) \n",
    "     \n",
    "    for index, row in Df2.iterrows():\n",
    "        Bags = set(StringToList_Nonums(str(row['question1'])) + StringToList_Nonums(str(row['question2'])))\n",
    "        for word in Bags:\n",
    "            PossibleNewWord(word, Dictionary, Dictionary2, RepeatedWords)  \n",
    "\n",
    "\n",
    "            \n",
    "## IMPORTANT: Explanation of the variables and quotients in the Dictionaries (/hash tables).\n",
    "# 'Words': each word of the dictionary\n",
    "# 'Frequency': Amount of rows from the original document in which 'word' appears,\n",
    "# 'Frequency1': Amount of rows in which 'word' appears in exactly one of the two questions,\n",
    "# 'NonDuplicate': Amount of times in which 'word' appears in exactly one of the two questions AND the questions are non duplicate,\n",
    "# 'Quotient1': NonDuplicate/Frequency1. \n",
    "# 'Frequency2': Amount of times in which 'word' appears in both questions\n",
    "# 'Quotient2': Duplicate/Frequency2.\n",
    "# 'Duplicate': Amount of times in which 'word' appears in both questions AND the questions are duplicate\n",
    "def CreateDictionary(Df1, Df2): #  Creates a Dictionary (hash table) that contains every possible word from Df1, Df2 and rates them \n",
    "    Dictionary = {}    \n",
    "    Dictionary2 = {}\n",
    "    RepeatedWords = {}\n",
    "    \n",
    "    Frequency1={}        \n",
    "    Frequency2={}\n",
    "    Duplicate={}\n",
    "    NonDuplicate={}\n",
    "\n",
    "    for index, row in Df1.iterrows():\n",
    "        isduplicate = int(row['is_duplicate'])\n",
    "        Bag1= StringToList_Nonums( str(row['question1']) )\n",
    "        Bag2= StringToList_Nonums( str(row['question2']) )\n",
    "        MergedSet = set(FuzzyUnion(Bag1, Bag2))\n",
    "\n",
    "        if index % 1000==1: ## Just to have an idea of the time left\n",
    "            clear_output()\n",
    "            print \"Row : \", index-1 , \"/\", Df1.shape[0]        \n",
    "        \n",
    "        \n",
    "        for word in MergedSet:\n",
    "            representative = FuzzyFindRepresentative(word, Frequency1)\n",
    "\n",
    "            if representative == \"\": ## We do not have a similar word in Frequency1\n",
    "                representative = word\n",
    "                Frequency1[representative] = 0\n",
    "                Frequency2[representative]= 0\n",
    "                Duplicate[representative]= 0\n",
    "                NonDuplicate[representative]=0\n",
    "\n",
    "            if np.logical_xor( FuzzyWordInList(word, Bag1), FuzzyWordInList(word, Bag2)): ## this is (word in Bag1) orex (word in Bag2)\n",
    "                Frequency1[representative] = Frequency1[representative] +1\n",
    "                if isduplicate==0:\n",
    "                    NonDuplicate[representative] = NonDuplicate[representative] +1  \n",
    "\n",
    "            if FuzzyWordInList(word, Bag1 ) and  FuzzyWordInList(word, Bag2):             ## The word is in both bags\n",
    "                Frequency2[representative] = Frequency2[representative] +1\n",
    "                if isduplicate==1: ## If a word is in both questions we check if that somehow implies both questions match.\n",
    "                    Duplicate[representative] = Duplicate[representative] +1            \n",
    "\n",
    "\n",
    "    ## We now filter the words in which we do not have a lot of information and create our Dictionary        \n",
    "    for word in Frequency1:\n",
    "        if (Frequency1[word]>20) and (Frequency2[word]>20):\n",
    "            Quotient1 = float(NonDuplicate[word])/Frequency1[word]\n",
    "            Quotient2 = float(Duplicate[word])/Frequency2[word]\n",
    "            Quotient1 = float(\"%.3f\" % Quotient1)\n",
    "            Quotient2 = float(\"%.3f\" % Quotient2)\n",
    "            Dictionary[word] = [Quotient1, Quotient2]        \n",
    "\n",
    "    DictionaryToCSV(Dictionary, \"MainWords.csv\")                       # This creates Dictionary1 that rates many of the words in  trainDf               \n",
    "    FeedDictionary(Df1, Df2, Dictionary, Dictionary2, RepeatedWords)   # We create a new dictionary (Dictionary2) rating all the words not in Dictionary1\n",
    "\n",
    "    for word in Dictionary2:                                           # We merge the two dictionaries\n",
    "        Quotients = Dictionary2[word]\n",
    "        Dictionary[word]= Dictionary2[word]\n",
    "\n",
    "    DictionaryToCSV(Dictionary, \"Dictionary.csv\")                      #We save the enlarged Dictionary to a .csv \n",
    "    RepeatedWordsToCSV(RepeatedWords, \"RepeatedWords.csv\")             #A file containing words that were found to be different\n",
    "    return Dictionary ## returns the actual hash table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "###############################             MAIN                 ################################################\n",
    "#################################################################################################################\n",
    "#################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading data \n",
    "dftrain = pd.DataFrame.from_csv(\"/data/train_tiny.csv\")\n",
    "dftest = pd.DataFrame.from_csv(\"/data/test_tiny.csv\")\n",
    "Dictionary = CreateDictionary(dftrain, dftest); ## Creates Dictionary.csv  SimilarWords.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating the dictionary \n",
    "#Dictionary = LoadDictionary() ## If Dictionary.csv already exists we just load it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
