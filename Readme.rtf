{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 ArialMT;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red26\green26\blue26;\red255\green255\blue255;
\red16\green60\blue192;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c13333\c13333\c13333;\cssrgb\c100000\c100000\c100000;
\cssrgb\c6667\c33333\c80000;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\b\fs29\fsmilli14667 \cf2 \expnd0\expndtw0\kerning0
"""\
Quora pairs Kaggle competition\
Third Quora Submission\
@author: Luis Duque\
luisduque440@gmail.com\
"""\
\
ABOUT THE PROJECT
\f1\b0\fs24 \

\f0\fs29\fsmilli14667 This project was created to work in the Quora Question Pairs Kaggle competition
\f1\fs24 \

\f0\fs29\fsmilli14667 (see details: https://www.kaggle.com/c/quora-question-pairs) 
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 Basically Quora released a training dataset with more than 400K pairs of questions in which it was known which questions were similar. \'a0The test data set consisted of more than 2M pairs of questions.
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 Example 1:
\f1\fs24 \

\f0\fs29\fsmilli14667 Q1: Is Obama giving a speech to the press today?
\f1\fs24 \

\f0\fs29\fsmilli14667 Q2: Is the president talking with the journalists today?
\f1\fs24 \

\f0\fs29\fsmilli14667 Q3: What time is it?
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 The Q1 and Q2 have similar meaning but Q2 and Q3 do not have a similar meaning.
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\b\fs29\fsmilli14667 \cf2 MY APPROACH
\f1\b0\fs24 \

\f0\fs29\fsmilli14667 I constructed around 125 features that can be divided in the following groups
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 * Very basic features: features involving the size of the questions, the number of words, the number of words not including stop words, number of question marks, number of commas, number of capital letters, flags for the most common first words (are, is, what, would, why, ..) 
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 * Naive Bayes/
\fs28 \cf3 \cb4 TFIDF
\fs29\fsmilli14667 \cf2 \cb1  - based features: some words are expected to be decisive when they are in one question but not in the other. Think about proper nouns like Obama, Trump, Armstrong, ....; it is intuitively less likely that two questions match provided that one of them has the word Trump and the other one does not. We initially rated the importance of each word in the training data set \'a0using a TFDIF (see wikipedia) and then extended this rating to words in the test dataset set using a pre trained word2vect model. We used this rating in order to create a set of features for the words that were in both questions of the pair and another set of features for the words that were in exactly one of the questions. 
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 * Parts of Speech-based features: We used NLTK (natural language toolkit) in python in order to extract the parts of speech of each question (the verbs, adverbs, nouns, pronouns, ... ) and then measured the distance of the part of speech of each question using different distances: Jaccard, WordMover, Cosine.
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 * Abhishel Thakur Features: he shared these features during the competition and many of the top teams were also using them, many of these features overlap with the ones explained before. See: {\field{\*\fldinst{HYPERLINK "https://github.com/abhishekkrthakur/is_that_a_duplicate_quora_question"}}{\fldrslt \cf5 \ul \ulc5 https://github.com/abhishekkrthakur/is_that_a_duplicate_quora_question}}
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 In order to make the classification I used Random Forests 
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\b\fs29\fsmilli14667 \cf2 POTENTIAL IMPROVEMENTS
\f1\b0\fs24 \

\f0\fs29\fsmilli14667 * The document {\field{\*\fldinst{HYPERLINK "https://medium.com/@InDataLabs/how-to-win-kaggle-competition-based-on-an-nlp-task-not-being-an-nlp-expert-58944df5644c"}}{\fldrslt \cf5 \ul \ulc5 https://medium.com/@InDataLabs/how-to-win-kaggle-competition-based-on-an-nlp-task-not-being-an-nlp-expert-58944df5644c}} \'a0\'a0explains how to create some features that were used by many groups during the competition (and shared between them) that might be interesting to include. A family of this features referred in the document as \'93magic features\'94 seams to be very relevant to the competition even though it is very dependent on the way the data set was provided and the way in which they organized the document.
\f1\fs24 \
\pard\pardeftab720\sl280\qj\partightenfactor0
\cf2 \
\pard\pardeftab720\sl400\qj\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 * Creating an ensemble of trees using Gradient Boosting seams to be a very popular technique amongst Kagglers that very often outperforms Random Forests. It would be interesting to run XGBoost with the features explained before.
\f1\fs24 \
}